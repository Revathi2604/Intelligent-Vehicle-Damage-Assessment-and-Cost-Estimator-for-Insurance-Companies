{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "x6zkmPODW4Jh"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Z2l29u7oXf5e"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "shear_range = 0.1,\n",
        "zoom_range = 0.1,\n",
        "horizontal_flip = True)\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHw6bSrjXlN-",
        "outputId": "abc858c3-2933-4e4e-8161-de95ea05385c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 979 images belonging to 3 classes.\n",
            "Found 979 images belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/Dataset/Car damage/body/training',\n",
        "target_size = (224, 224),\n",
        "batch_size = 10,\n",
        "class_mode = 'categorical')\n",
        "test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/Dataset/Car damage/body/training',\n",
        "target_size = (224, 224),\n",
        "batch_size = 10,\n",
        "class_mode = 'categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KO6R0-T_X1zX"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Lambda, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4Nd-kgHWer-A"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = [224, 224]\n",
        "train_path = '/content/drive/MyDrive/Dataset/Car damage/body/training'\n",
        "valid_path = '/content/drive/MyDrive/Dataset/Car damage/body/validation'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pVzGdvgWolTL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf67115a-9c49-41f2-df58-83d43409a3a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "vgg16 = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IjRbOYRde9Hd"
      },
      "outputs": [],
      "source": [
        "for layer in vgg16.layers:\n",
        "  layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9bq3M8ClfSgs"
      },
      "outputs": [],
      "source": [
        "folders = glob('/content/drive/MyDrive/Dataset/Car damage/body/training/*')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBSI87XwfYvF",
        "outputId": "8f029519-e159-4fa4-9243-f3c4d8e2a9b0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/Dataset/Car damage/body/training/02-side',\n",
              " '/content/drive/MyDrive/Dataset/Car damage/body/training/01-rear',\n",
              " '/content/drive/MyDrive/Dataset/Car damage/body/training/00-front']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "nq5b5ZxlfiWe"
      },
      "outputs": [],
      "source": [
        "x = Flatten() (vgg16.output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jwauhpkgnLH",
        "outputId": "6eb8c645-e43e-4d43-cc2a-62337e5e4d3e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "len(folders)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "PS-U2sW2gqvU"
      },
      "outputs": [],
      "source": [
        "prediction = Dense(len(folders), activation='softmax')(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "F2usUFAFo3-o"
      },
      "outputs": [],
      "source": [
        "model = Model(inputs=vgg16.input, outputs=prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TS8fUT1Oo8mN",
        "outputId": "100a4805-0dac-4811-bcb4-fb11ed97311e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 3)                 75267     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,789,955\n",
            "Trainable params: 75,267\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ncWW2y5opCFu"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "loss='categorical_crossentropy',\n",
        "optimizer='adam',\n",
        "metrics=['accuracy']\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFoKWS1mpGHF",
        "outputId": "8004f40e-9b61-4dd5-c819-77247a75ce0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "98/98 [==============================] - 1025s 10s/step - loss: 1.3726 - accuracy: 0.5087 - val_loss: 0.6431 - val_accuracy: 0.7671\n",
            "Epoch 2/25\n",
            "98/98 [==============================] - 1022s 10s/step - loss: 0.7143 - accuracy: 0.7201 - val_loss: 0.4365 - val_accuracy: 0.8243\n",
            "Epoch 3/25\n",
            "98/98 [==============================] - 1024s 10s/step - loss: 0.4599 - accuracy: 0.8304 - val_loss: 0.3137 - val_accuracy: 0.8836\n",
            "Epoch 4/25\n",
            "98/98 [==============================] - 1021s 10s/step - loss: 0.3622 - accuracy: 0.8631 - val_loss: 0.2275 - val_accuracy: 0.9142\n",
            "Epoch 5/25\n",
            "98/98 [==============================] - 1029s 11s/step - loss: 0.2830 - accuracy: 0.8825 - val_loss: 0.2081 - val_accuracy: 0.9254\n",
            "Epoch 6/25\n",
            "98/98 [==============================] - 1025s 11s/step - loss: 0.2023 - accuracy: 0.9305 - val_loss: 0.1584 - val_accuracy: 0.9489\n",
            "Epoch 7/25\n",
            "98/98 [==============================] - 1026s 11s/step - loss: 0.1646 - accuracy: 0.9510 - val_loss: 0.1743 - val_accuracy: 0.9438\n",
            "Epoch 8/25\n",
            "98/98 [==============================] - 1028s 11s/step - loss: 0.1497 - accuracy: 0.9479 - val_loss: 0.1106 - val_accuracy: 0.9673\n",
            "Epoch 9/25\n",
            "98/98 [==============================] - 1025s 11s/step - loss: 0.1784 - accuracy: 0.9418 - val_loss: 0.1361 - val_accuracy: 0.9428\n",
            "Epoch 10/25\n",
            "98/98 [==============================] - 1025s 11s/step - loss: 0.1089 - accuracy: 0.9632 - val_loss: 0.0569 - val_accuracy: 0.9888\n",
            "Epoch 11/25\n",
            "98/98 [==============================] - 1027s 11s/step - loss: 0.1081 - accuracy: 0.9683 - val_loss: 0.0623 - val_accuracy: 0.9888\n",
            "Epoch 12/25\n",
            "98/98 [==============================] - 1028s 11s/step - loss: 0.1039 - accuracy: 0.9694 - val_loss: 0.0470 - val_accuracy: 0.9949\n",
            "Epoch 13/25\n",
            "98/98 [==============================] - 1029s 11s/step - loss: 0.0845 - accuracy: 0.9745 - val_loss: 0.0444 - val_accuracy: 0.9928\n",
            "Epoch 14/25\n",
            "98/98 [==============================] - 1032s 11s/step - loss: 0.0922 - accuracy: 0.9796 - val_loss: 0.0351 - val_accuracy: 0.9908\n",
            "Epoch 15/25\n",
            "98/98 [==============================] - 1029s 11s/step - loss: 0.0657 - accuracy: 0.9837 - val_loss: 0.0533 - val_accuracy: 0.9918\n",
            "Epoch 16/25\n",
            "98/98 [==============================] - 1031s 11s/step - loss: 0.1250 - accuracy: 0.9561 - val_loss: 0.1176 - val_accuracy: 0.9602\n",
            "Epoch 17/25\n",
            "98/98 [==============================] - 1032s 11s/step - loss: 0.0628 - accuracy: 0.9908 - val_loss: 0.1077 - val_accuracy: 0.9673\n",
            "Epoch 18/25\n",
            "98/98 [==============================] - 1027s 11s/step - loss: 0.0585 - accuracy: 0.9847 - val_loss: 0.0280 - val_accuracy: 0.9959\n",
            "Epoch 19/25\n",
            "98/98 [==============================] - 1031s 11s/step - loss: 0.0459 - accuracy: 0.9918 - val_loss: 0.0322 - val_accuracy: 0.9949\n",
            "Epoch 20/25\n",
            "98/98 [==============================] - 1031s 11s/step - loss: 0.0590 - accuracy: 0.9918 - val_loss: 0.0253 - val_accuracy: 0.9949\n",
            "Epoch 21/25\n",
            "98/98 [==============================] - 1028s 11s/step - loss: 0.0426 - accuracy: 0.9939 - val_loss: 0.0263 - val_accuracy: 0.9959\n",
            "Epoch 22/25\n",
            "98/98 [==============================] - 1024s 10s/step - loss: 0.0401 - accuracy: 0.9928 - val_loss: 0.0373 - val_accuracy: 0.9949\n",
            "Epoch 23/25\n",
            "98/98 [==============================] - 1030s 11s/step - loss: 0.0620 - accuracy: 0.9867 - val_loss: 0.0211 - val_accuracy: 0.9959\n",
            "Epoch 24/25\n",
            "98/98 [==============================] - 1028s 11s/step - loss: 0.0316 - accuracy: 0.9959 - val_loss: 0.0206 - val_accuracy: 0.9959\n",
            "Epoch 25/25\n",
            "98/98 [==============================] - 1030s 11s/step - loss: 0.1129 - accuracy: 0.9602 - val_loss: 0.1743 - val_accuracy: 0.9418\n"
          ]
        }
      ],
      "source": [
        "r = model.fit_generator(\n",
        "training_set,\n",
        "validation_data=test_set,\n",
        "epochs=25,\n",
        "steps_per_epoch=len(training_set),\n",
        "validation_steps=len(test_set)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model.save('/content/drive/MyDrive/Dataset/Car damage/body')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmzzbQ3wM8jo",
        "outputId": "c669087c-ba95-4302-9d7c-2ab7fd15f787"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import cv2\n",
        "from skimage.transform import resize"
      ],
      "metadata": {
        "id": "FAe4mw9dNW5v"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('/content/drive/MyDrive/Dataset/Car damage/body')\n"
      ],
      "metadata": {
        "id": "eYkLK9bRNeli"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect(frame):\n",
        "  img = cv2.resize(frame,(224,224))\n",
        "  img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  if(np.max(img)>1):\n",
        "    img = img/255.0\n",
        "  img = np.array([img])\n",
        "  prediction = model.predict(img)\n",
        "  label = [\"front\",\"rear\",\"side\"]\n",
        "  preds = label[np.argmax(prediction)]\n",
        "  return preds\n",
        "\n"
      ],
      "metadata": {
        "id": "4NAlnFuJNsy9"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "H4Tjp5GbOMi5"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = \"/content/drive/MyDrive/Dataset/Car damage/body/training/00-front/0003.JPEG\"\n",
        "image = cv2.imread(data)\n",
        "print(detect(image))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crsK80DbOTpF",
        "outputId": "85a6e808-2a80-4e82-f3c1-28cf712a08c0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 769ms/step\n",
            "front\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}